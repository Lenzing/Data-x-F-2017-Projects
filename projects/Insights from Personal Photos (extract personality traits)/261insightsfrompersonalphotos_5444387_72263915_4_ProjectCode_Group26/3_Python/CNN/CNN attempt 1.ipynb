{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress TensorFlow and Keras warnings for cleaner output\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The backend is: tensorflow\n",
      "tf\n",
      "1.0.1\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('tf') # note that we need to have tensorflow dimension ordering still because of the weights.\n",
    "print('The backend is:',K.backend())\n",
    "import tensorflow as tf\n",
    "print(K.image_dim_ordering()) # should say tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant packages\n",
    "import h5py\n",
    "import os, cv2, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "#from matplotlib import ticker\n",
    "#import seaborn as sns\n",
    "%matplotlib inline \n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dropout, Flatten, Convolution2D, MaxPooling2D, Dense, Activation, ZeroPadding2D\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
    "from keras.models import model_from_json\n",
    "from keras.preprocessing import image\n",
    "\n",
    "from IPython.display import Image, display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define variables\n",
    "TRAIN_DIR = './data/train/'\n",
    "VAL_DIR = './data/validation/'\n",
    "TEST_DIR = './data/test/' #one mixed category\n",
    "\n",
    "img_width, img_height = 150, 150\n",
    "\n",
    "n_train_samples = 1976\n",
    "n_validation_samples = 800\n",
    "n_epoch = 30\n",
    "n_test_samples = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This can take ~20mins to run\n",
    "#  Run model once to record the bottleneck features using image data generators:\n",
    "\n",
    "def save_bottleneck_features():\n",
    "\n",
    "    from keras import applications\n",
    "    model = applications.vgg16.VGG16(include_top=False, weights='imagenet', \\\n",
    "                                     input_tensor=None, input_shape=(img_width, img_height,3))\n",
    "    \n",
    "    print('TensorFlow VGG16 model architecture loaded')    \n",
    "    \n",
    "    datagen = ImageDataGenerator(rescale=1./255)\n",
    "    \n",
    "    def generate_features(DIR,n_samples,name_str):\n",
    "\n",
    "        print('Generate '+name_str+' image features')\n",
    "\n",
    "        generator = datagen.flow_from_directory(DIR,\n",
    "            target_size=(img_width, img_height),\n",
    "            batch_size=32,\n",
    "            class_mode=None, # this means our generator will only yield batches of data, no labels\n",
    "            shuffle=False) # our data will be in order, so all first 1000 images will be cats, then 1000 dogs\n",
    "        \n",
    "        features = model.predict_generator(generator, n_samples)\n",
    "        \n",
    "        np.save('features_'+name_str+'.npy', features) # save bottleneck features to file\n",
    "    \n",
    "    #generate_features(TEST_DIR, n_test_samples, 'test')\n",
    "    generate_features(TRAIN_DIR, n_train_samples, 'train')\n",
    "    #generate_features(VAL_DIR, n_validation_samples, 'validation')\n",
    "    \n",
    "    print('\\nDone! Bottleneck features have been saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "TensorFlow VGG16 model architecture loaded\n",
      "Generate train image features\n",
      "Found 1976 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "save_bottleneck_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.3.0\n"
     ]
    }
   ],
   "source": [
    "# Extra\n",
    "# Obtain class labels and binary classification for validation data\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "val_gen = datagen.flow_from_directory(VAL_DIR,target_size=(img_width, img_height),\n",
    "                                        batch_size=32,class_mode=None,shuffle=False)\n",
    "\n",
    "val_labels = val_gen.classes\n",
    "\n",
    "print('\\nClassifications:\\n',val_gen.class_indices)\n",
    "print('\\nClass labels:\\n',val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in bottleneck features\n",
    "# Run the code below to train your CNN with the training data\n",
    "\n",
    "def train_model():\n",
    "    train_data = np.load('features_train.npy')\n",
    "    # the features were saved in order, so recreating the labels is easy\n",
    "    train_labels = np.array([0] * (n_train_samples // 2) + [1] * (n_train_samples // 2))\n",
    "\n",
    "    validation_data = np.load('features_validation.npy')\n",
    "    # same as val_labels above\n",
    "    validation_labels = np.array([0] * (n_validation_samples // 2) + [1] * (n_validation_samples // 2))\n",
    "\n",
    "    # Add top layers trained ontop of extracted VGG features\n",
    "    # Small fully connected model trained on top of the stored features\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=train_data.shape[1:]))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    '''\n",
    "    #We end the model with a single unit and a sigmoid activation, which is perfect for a binary classification. \n",
    "    #To go with it we will also use the binary_crossentropy loss to train our model.\n",
    "\n",
    "    '''\n",
    "    model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    model.fit(train_data, train_labels,\n",
    "              nb_epoch=n_epoch, batch_size=32,\n",
    "              validation_data=(validation_data, validation_labels),\n",
    "              shuffle=True) # fit the model\n",
    "\n",
    "    # Save weights to disk\n",
    "\n",
    "    # Save model architecture to disk\n",
    "    model_json = model.to_json()\n",
    "    with open(\"mod_appendix.json\", \"w\") as json_file: # save model\n",
    "        json_file.write(model_json)\n",
    "    \n",
    "    # Save model weights\n",
    "    model.save_weights(\"catvsdogs_VGG16_pretrained_tf_top.h5\") # save weights\n",
    "    print(\"Saved model to disk\")\n",
    "    print('Done!')\n",
    "    \n",
    "    return(model)\n",
    "    \n",
    "model = train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data = np.load('features_validation.npy')\n",
    "\n",
    "val_pred_class = model.predict_classes(validation_data,verbose=0) # predict image classes \n",
    "val_pred_prob = model.predict_proba(validation_data,verbose=0) # predict image probabilities\n",
    "\n",
    "print('Accuracy on validation set: ',np.mean(val_pred_class.ravel()==val_labels)*100,'%')\n",
    "\n",
    "print('\\nVal loss & val_acc')\n",
    "print(model.evaluate(validation_data,val_labels,verbose=0))\n",
    "# First number is validation loss, loss of the objective function\n",
    "# Second number validation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative\n",
    "print('Model accuracy on validation set:',model.evaluate(validation_data,val_labels,verbose=0)[1]*100,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Print try images:\n",
    "\n",
    "# Use the model trained in Problem 1 to classify the test data images.\n",
    "# Create a function that loads one image from the test data and then predicts\n",
    "# if it is a cat or a dog and with what probability it thinks it is a cat or a dog\n",
    "#\n",
    "# Use variable test_data to make predictions\n",
    "# Use list test_images to obtain the file name for all images (Note: test_images[0] corresponds to test_data[0])\n",
    "# Use function plot_pic(img) to plot the image file\n",
    "\n",
    "## Load in processed images feature to feed into bottleneck model\n",
    "\n",
    "test_data = np.load('features_test.npy')\n",
    "\n",
    "test_images =  [TEST_DIR+'catvdog/'+img for img in os.listdir(TEST_DIR+'catvdog/')]\n",
    "\n",
    "def read_image(file_path):\n",
    "    # For image visualization\n",
    "    im = np.array(Image.open(file_path))\n",
    "    # img = cv2.imread(file_path, cv2.IMREAD_COLOR) #cv2.IMREAD_GRAYSCALE\n",
    "    return im\n",
    "\n",
    "def plot_pic(img):\n",
    "    # Plot openCV pic\n",
    "    pic = read_image(img)    \n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.imshow(pic)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Answer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') # filter eventual warning\n",
    "\n",
    "def predict(mod,i=0,r=None):\n",
    "    if r==None:\n",
    "        r=[i]\n",
    "        \n",
    "    for idx in r:\n",
    "        class_pred = mod.predict_classes(test_data,verbose=0)[idx]\n",
    "        prob_pred = mod.predict_proba(test_data,verbose=0)[idx]\n",
    "        \n",
    "        if class_pred ==0:\n",
    "            prob_pred = 1-prob_pred\n",
    "            class_guess='CAT'\n",
    "        else:\n",
    "            class_guess='DOG'\n",
    "        \n",
    "        print('\\n\\nI think this is a ' + class_guess + ' with ' +str(round(float(prob_pred)*100,5)) + '% probability')\n",
    "        if test_images[idx]=='./data/test/catvdog/.DS_Store':\n",
    "            continue\n",
    "        plot_pic(test_images[idx])\n",
    "\n",
    "predict(model,r=range(0,len(test_data)-64)) # seems to be doing really well"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
