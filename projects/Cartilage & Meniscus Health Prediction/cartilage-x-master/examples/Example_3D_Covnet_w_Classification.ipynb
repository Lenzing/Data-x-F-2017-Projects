{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dicom'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-dc3b425e82b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mdicom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'dicom'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dicom\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import math\n",
    "\n",
    "dataDirectory = 'Lung_Cancer/stage1/stage1/'\n",
    "lungPatients = os.listdir(dataDirectory)\n",
    "labels = pd.read_csv('Lung_Cancer/stage1_labels/stage1_labels.csv', index_col=0)\n",
    "size = 50\n",
    "NoSlices = 20\n",
    "\n",
    "\n",
    "def chunks(l, n):\n",
    "    count = 0\n",
    "    for i in range(0, len(l), n):\n",
    "        if (count < NoSlices):\n",
    "            yield l[i:i + n]\n",
    "            count = count + 1\n",
    "\n",
    "\n",
    "def mean(l):\n",
    "    return sum(l) / len(l)\n",
    "\n",
    "\n",
    "def dataProcessing(patient, labels_df, size=50, noslices=20, visualize=False):\n",
    "    label = labels_df.get_value(patient, 'cancer')\n",
    "    path = dataDirectory + patient\n",
    "    slices = [dicom.read_file(path + '/' + s) for s in os.listdir(path)]\n",
    "    slices.sort(key=lambda x: int(x.ImagePositionPatient[2]))\n",
    "\n",
    "    new_slices = []\n",
    "    slices = [cv2.resize(np.array(each_slice.pixel_array), (size, size)) for each_slice in slices]\n",
    "\n",
    "    chunk_sizes = math.floor(len(slices) / noslices)\n",
    "    for slice_chunk in chunks(slices, chunk_sizes):\n",
    "        slice_chunk = list(map(mean, zip(*slice_chunk)))\n",
    "        new_slices.append(slice_chunk)\n",
    "\n",
    "    if label == 1:\n",
    "        label = np.array([0, 1])\n",
    "    elif label == 0:\n",
    "        label = np.array([1, 0])\n",
    "    return np.array(new_slices), label\n",
    "\n",
    "\n",
    "imageData = []\n",
    "for num, patient in enumerate(lungPatients):\n",
    "    if num % 100 == 0:\n",
    "        print('Saved -', num)\n",
    "    try:\n",
    "        img_data, label = dataProcessing(patient, labels, size=size, noslices=NoSlices)\n",
    "        imageData.append([img_data, label,patient])\n",
    "    except KeyError as e:\n",
    "        print('Data is unlabeled')\n",
    "\n",
    "np.save('imageDataNew-{}-{}-{}.npy'.format(size, size, NoSlices), imageData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import tflearn\n",
    "from tflearn.layers.conv import conv_3d, max_pool_3d\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.estimator import regression\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "imageData = np.load('imageDataNew-50-50-20.npy')\n",
    "trainingData = imageData[0:800]\n",
    "validationData = imageData[-200:-100]\n",
    "\n",
    "x = tf.placeholder('float')\n",
    "y = tf.placeholder('float')\n",
    "size = 50\n",
    "keep_rate = 0.8\n",
    "NoSlices = 20\n",
    "\n",
    "\n",
    "def convolution3d(x, W):\n",
    "    return tf.nn.conv3d(x, W, strides=[1, 1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "\n",
    "def maxpooling3d(x):\n",
    "    return tf.nn.max_pool3d(x, ksize=[1, 2, 2, 2, 1], strides=[1, 2, 2, 2, 1], padding='SAME')\n",
    "\n",
    "\n",
    "def cnn(x):\n",
    "    x = tf.reshape(x, shape=[-1, size, size, NoSlices, 1])\n",
    "    convolution1 = tf.nn.relu(\n",
    "        convolution3d(x, tf.Variable(tf.random_normal([3, 3, 3, 1, 32]))) + tf.Variable(tf.random_normal([32])))\n",
    "    convolution1 = maxpooling3d(convolution1)\n",
    "    convolution2 = tf.nn.relu(\n",
    "        convolution3d(convolution1, tf.Variable(tf.random_normal([3, 3, 3, 32, 64]))) + tf.Variable(\n",
    "            tf.random_normal([64])))\n",
    "    convolution2 = maxpooling3d(convolution2)\n",
    "    convolution3 = tf.nn.relu(\n",
    "        convolution3d(convolution2, tf.Variable(tf.random_normal([3, 3, 3, 64, 128]))) + tf.Variable(\n",
    "            tf.random_normal([128])))\n",
    "    convolution3 = maxpooling3d(convolution3)\n",
    "    convolution4 = tf.nn.relu(\n",
    "        convolution3d(convolution3, tf.Variable(tf.random_normal([3, 3, 3, 128, 256]))) + tf.Variable(\n",
    "            tf.random_normal([256])))\n",
    "    convolution4 = maxpooling3d(convolution4)\n",
    "    convolution5 = tf.nn.relu(\n",
    "        convolution3d(convolution4, tf.Variable(tf.random_normal([3, 3, 3, 256, 512]))) + tf.Variable(\n",
    "            tf.random_normal([512])))\n",
    "    convolution5 = maxpooling3d(convolution4)\n",
    "    fullyconnected = tf.reshape(convolution5, [-1, 1024])\n",
    "    fullyconnected = tf.nn.relu(\n",
    "        tf.matmul(fullyconnected, tf.Variable(tf.random_normal([1024, 1024]))) + tf.Variable(tf.random_normal([1024])))\n",
    "    fullyconnected = tf.nn.dropout(fullyconnected, keep_rate)\n",
    "    output = tf.matmul(fullyconnected, tf.Variable(tf.random_normal([1024, 2]))) + tf.Variable(tf.random_normal([2]))\n",
    "    return output\n",
    "\n",
    "\n",
    "def network(x):\n",
    "    prediction = cnn(x)\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction, labels=y))\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=1e-3).minimize(cost)\n",
    "    epochs = 10\n",
    "    with tf.Session() as session:\n",
    "        session.run(tf.global_variables_initializer())\n",
    "        for epoch in range(epochs):\n",
    "            epoch_loss = 0\n",
    "            for data in trainingData:\n",
    "                try:\n",
    "                    X = data[0]\n",
    "                    Y = data[1]\n",
    "                    _, c = session.run([optimizer, cost], feed_dict={x: X, y: Y})\n",
    "                    epoch_loss += c\n",
    "                except Exception as e:\n",
    "                    pass\n",
    "\n",
    "            correct = tf.equal(tf.argmax(prediction, 1), tf.argmax(y, 1))\n",
    "           # if tf.argmax(prediction, 1) == 0:\n",
    "            accuracy = tf.reduce_mean(tf.cast(correct, 'float'))\n",
    "            print('Epoch', epoch + 1, 'completed out of', epochs, 'loss:', epoch_loss)\n",
    "            # print('Correct:',correct.eval({x:[i[0] for i in validationData], y:[i[1] for i in validationData]}))\n",
    "            print('Accuracy:', accuracy.eval({x: [i[0] for i in validationData], y: [i[1] for i in validationData]}))\n",
    "        print('Final Accuracy:', accuracy.eval({x: [i[0] for i in validationData], y: [i[1] for i in validationData]}))\n",
    "        patients = []\n",
    "        actual = []\n",
    "        predicted = []\n",
    "\n",
    "        finalprediction = tf.argmax(prediction, 1)\n",
    "        actualprediction = tf.argmax(y, 1)\n",
    "        for i in range(len(validationData)):\n",
    "            patients.append(validationData[i][2])\n",
    "        for i in finalprediction.eval({x: [i[0] for i in validationData], y: [i[1] for i in validationData]}):\n",
    "            if(i==1):\n",
    "                predicted.append(\"Cancer\")\n",
    "            else:\n",
    "                predicted.append(\"No Cancer\")\n",
    "        for i in actualprediction.eval({x: [i[0] for i in validationData], y: [i[1] for i in validationData]}):\n",
    "            if(i==1):\n",
    "                actual.append(\"Cancer\")\n",
    "            else:\n",
    "                actual.append(\"No Cancer\")\n",
    "        for i in range(len(patients)):\n",
    "            print(\"Patient: \",patients[i])\n",
    "            print(\"Actual: \", actual[i])\n",
    "            print(\"Predicted: \", predicted[i])\n",
    "\n",
    "        from sklearn.metrics import confusion_matrix\n",
    "        y_actual = pd.Series(\n",
    "            (actualprediction.eval({x: [i[0] for i in validationData], y: [i[1] for i in validationData]})),\n",
    "            name='Actual')\n",
    "        y_predicted = pd.Series(\n",
    "            (finalprediction.eval({x: [i[0] for i in validationData], y: [i[1] for i in validationData]})),\n",
    "            name='Predicted')\n",
    "        df_confusion = pd.crosstab(y_actual, y_predicted)\n",
    "        print(df_confusion)\n",
    "\n",
    "        def plot_confusion_matrix(df_confusion, title='Confusion matrix', cmap=plt.cm.gray_r):\\\n",
    "            \n",
    "            plt.matshow(df_confusion, cmap=cmap)\n",
    "            plt.colorbar()\n",
    "            tick_marks = np.arange(len(df_confusion.columns))\n",
    "            plt.xticks(tick_marks, df_confusion.columns, rotation=45)\n",
    "            plt.yticks(tick_marks, df_confusion.index)\n",
    "            plt.ylabel(df_confusion.index.name)\n",
    "            plt.xlabel(df_confusion.columns.name)\n",
    "            plt.show()\n",
    "        plot_confusion_matrix(df_confusion)\n",
    "network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
