{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/jeremy/anaconda/envs/venv/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The backend is: tensorflow\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('tf')\n",
    "print('The backend is:',K.backend())\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant packages\n",
    "import h5py\n",
    "import os, cv2, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dropout, Flatten, Convolution2D, MaxPooling2D, Dense, Activation, ZeroPadding2D, Conv2D\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
    "from keras.models import model_from_json\n",
    "from keras.preprocessing import image\n",
    "\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from IPython.display import Image, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading in the data\n",
    "\n",
    "# Loading in the index\n",
    "dropped = np.load(\"../../data/dropped.npy\")\n",
    "\n",
    "# Loading in the cropped 2D matrix\n",
    "mfc = np.load(\"../../data/z1.npy\")\n",
    "lfc = np.load(\"../../data/z2.npy\")\n",
    "\n",
    "# Loading in the augmentations\n",
    "mfc_aug = np.load(\"../../data/z1_aug_formatted.npy\")\n",
    "mfc_aug_2 = np.load(\"../../data/z1_fil_aug.npy\")\n",
    "mfc_aug_3 = np.load(\"../../data/z1_intensity.npy\")\n",
    "\n",
    "# Normalizing the data\n",
    "z1 = normalize(mfc, norm = \"max\")\n",
    "z2 = normalize(lfc, norm = \"max\")\n",
    "z3 = normalize(mfc_aug[0:1585], norm = \"max\")\n",
    "z4 = normalize(mfc_aug_2[0:1585], norm = \"max\")\n",
    "z5 = mfc_aug_3 # This one is already normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def matrix_to_df(matrix, augmentation = False):\n",
    "    df = pd.read_csv(\"../clean_all_path.csv\")\n",
    "\n",
    "    df['patient'] = df['mriFile'].apply(lambda f: os.path.splitext(os.path.basename(f))[0].split('_')[0])\n",
    "    df = df.drop(labels=[ 'mfcWorms', 'lfcWorms'],\n",
    "                axis=1)\n",
    "\n",
    "    np.shape(dropped)[0] + np.shape(matrix)[0] == df.shape[0]\n",
    "\n",
    "    df=df.drop(dropped, axis=0)\n",
    "\n",
    "    #Reseting indexes and forming x dataframe\n",
    "\n",
    "    df=df.reset_index()\n",
    "    df=df.drop(labels='index', axis=1)\n",
    "\n",
    "    x=pd.DataFrame(matrix).reset_index()\n",
    "    x=x.drop(labels='index', axis=1)\n",
    "\n",
    "\n",
    "    #Let's merge them into a single dataset to remove NaN values\n",
    "\n",
    "    df=df.merge(x,left_index=True,right_index=True)\n",
    "\n",
    "    #Removing NaN values\n",
    "\n",
    "    df[df['mfcBME'].isnull()]\n",
    "    df=df.drop([1356, 1565], axis=0)\n",
    "\n",
    "    df.isnull().sum().sum()\n",
    "\n",
    "\n",
    "    df['mfcBME'][df['mfcBME']>0]=1\n",
    "    \n",
    "    if augmentation:\n",
    "        df['set']=2\n",
    "    else:\n",
    "        df['set']=0\n",
    "\n",
    "    if not augmentation:\n",
    "        for i in df['patient'].unique():\n",
    "            if np.random.uniform(0,1)>0.8:\n",
    "                df.loc[df['patient']==i, 'set'] = 1\n",
    "    \n",
    "    if augmentation:\n",
    "    # Only use the minority data       \n",
    "        df = df[df[\"mfcBME\"] > 0]\n",
    "            \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeremy/anaconda/envs/venv/lib/python3.6/site-packages/ipykernel_launcher.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "baseline = matrix_to_df(z1)\n",
    "affine_aug = matrix_to_df(z3, True)\n",
    "filter_aug = matrix_to_df(z4, True)\n",
    "intensity_aug = matrix_to_df(z5, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = baseline\n",
    "# Append the augmentations\n",
    "# Uncomment to add augmentation data\n",
    "df = df.append(affine_aug)\n",
    "#df = df.append(filter_aug)\n",
    "#df = df.append(intensity_aug)\n",
    "\n",
    "# Splitting the dataset\n",
    "x_train = df[(df['set']==0) | (df['set'] == 2)].drop(['mriFile','segFile','mfcBME','lfcBME','patient','set'],axis=1)\n",
    "y_train = df[(df['set']==0) | (df['set'] == 2)]['mfcBME']\n",
    "x_test = df[df['set']==1].drop(['mriFile','segFile','mfcBME','lfcBME','patient', 'set'],axis=1)\n",
    "y_test = df[df['set']==1]['mfcBME']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training variables\n",
    "\n",
    "img_width, img_height = 120, 120\n",
    "input_shape = (img_width, img_height, 1)\n",
    "n_train_samples = len(z1)\n",
    "n_validation_samples = len(z1)\n",
    "epochs = 2\n",
    "batch_size = 50\n",
    "n_test_samples = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping training and testing data to fit model\n",
    "\n",
    "mfc_x_train = np.array(x_train)\n",
    "mfc_x_train = mfc_x_train.reshape(mfc_x_train.shape[0], img_width, img_height, 1)\n",
    "mfc_y_train = np.array(y_train)\n",
    "\n",
    "mfc_x_test = np.array(x_test)\n",
    "mfc_x_test = mfc_x_test.reshape(mfc_x_test.shape[0], img_width, img_height, 1)\n",
    "mfc_y_test = np.array(y_test)\n",
    "\n",
    "lfc_x_train = z2\n",
    "lfc_x_train = lfc_x_train.reshape(lfc_x_train.shape[0], img_width, img_height, 1)\n",
    "lfc_y_train = df[\"lfcBME\"]\n",
    "lfc_y_train = np.array(lfc_y_train).reshape((len(df), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating CNN\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=K.binary_crossentropy,\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(mfc_x_train, mfc_y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=1,\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test accuracy\n",
    "\n",
    "score = model.evaluate(mfc_x_test, mfc_y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test confusion matrix\n",
    "\n",
    "predictions = model.predict_classes(mfc_x_test)\n",
    "cm = confusion_matrix(mfc_y_test.reshape(len(mfc_y_test), 1), predictions)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation accuracy\n",
    "\n",
    "score = model.evaluate(mfc_x_train, mfc_y_train, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation confusion matrix\n",
    "\n",
    "predictions = model.predict_classes(mfc_x_train)\n",
    "cm = confusion_matrix(mfc_y_train.reshape(len(mfc_y_train), 1), predictions)\n",
    "cm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
